{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Overview\n",
    "\n",
    "# Objective\n",
    "\n",
    "The objective of this project is for you to demonstrate your mastery of the Machine Learning process\n",
    "**using Neural Networks**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission requirements\n",
    "\n",
    "The guidelines will be similar to the Midterm\n",
    "- you will write a procedure that takes raw data and produces predictions\n",
    "\n",
    "You will submit a *single* model for evaluation.\n",
    "\n",
    "**Demonstrate that all cells in your notebook work**\n",
    "\n",
    "The final cell in your notebook should print the message \"Done\"\n",
    "- `print(\"Done\")`\n",
    "- If we run your notebook and this last cell does not execute your submission will be inadequate\n",
    "\n",
    "## Testing\n",
    "\n",
    "*You must perform out of sample testing*.\n",
    "\n",
    "If you want to perform cross-validation in training, that is fine, but you\n",
    "must *also* test out of sample to show that you are not over-fitting.\n",
    "\n",
    "It is up to you to create the out of sample data that you feel best evaluates your model.\n",
    "\n",
    "We will create holdout data (that we will not show you) for grading.\n",
    "\n",
    "The procedure you write to make predictions should be able to work on the unseen holdout data\n",
    "(similar to how it should work for your test set but the holdout set has *no targets*)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data\n",
    "\n",
    "Data will be provided to you \n",
    "- as multiple files in a directory which we refer to as a *data directory*\n",
    "\n",
    "The reason for this is that the different files may convey different information.\n",
    "\n",
    "You will be responsible for deciding\n",
    "- which files to use\n",
    "- which fields within the files to use\n",
    "\n",
    "We will give you a data directory for training.\n",
    "\n",
    "# Submission guidelines\n",
    "\n",
    "Here are the basics, a code template that you must complete is in the following cells\n",
    "- you will be required to store  your model in a file\n",
    "- you will be required to write a procedure `MyModel` that takes two arguments\n",
    "    - `test_dir`\n",
    "        - this is a *relative path* to the holdout data directory\n",
    "    - `model_path`\n",
    "        - this is a *relative path* to the file containing your model\n",
    "- the holdout data directory is similar in structure to the training data directory\n",
    "    - but without target labels !  It is your job to predict these.\n",
    "- your procedure must produce predictions given this holdout data directory\n",
    "\n",
    "This means that your procedure must\n",
    "- prepare the files in the holdout data directory similar to the way that they were prepared in the training data directory\n",
    "\n",
    "We will provide you with a sample data directory that will resemble the holdout -- this is so that you\n",
    "may test the procedure you write for submission.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed submission guidelines\n",
    "\n",
    "\n",
    "In **addition to your notebook that trains/evaluates your model**, \n",
    "- please also submit an **archive file of the directory** whose name is stored in `model_path`, which \n",
    "contains your trained model.\n",
    "    - use `saveModel` to put your final, trained model in this directory\n",
    "- We will **not** train your model; we will only use the method `MyModel`\n",
    "    - which **you** will implement\n",
    "    - and which uses `loadModel` and the directory whose name is stored in `model_path`\n",
    "    - this will create the model that we will evaluate\n",
    "\n",
    "\n",
    "Here is a code template for you to complete\n",
    "- it will save your model (assuming it is in variable `my_model`)\n",
    "- it provides the specification for procedure `MyModel`, which *you must complete*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,SimpleRNN,LSTM,Dropout,BatchNormalization,Reshape\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPositive(x):\n",
    "    return x[x>0].sum()\n",
    "\n",
    "def addNegative(x):\n",
    "    return -x[x<0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_technical_indicators(dataset):\n",
    "   # Create 7 and 21 days Moving Average\n",
    "   dataset['ma7'] = dataset['Close'].rolling(window=7).mean()\n",
    "   dataset['ma21'] = dataset['Close'].rolling(window=21).mean()\n",
    "   \n",
    "   # Create MACD\n",
    "   dataset['26ema'] = dataset['Close'].ewm(span=26).mean()\n",
    "   dataset['12ema'] = dataset['Close'].ewm(span=12).mean()\n",
    "   dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n",
    "\n",
    "   # Create Bollinger Bands\n",
    "   dataset['20sd'] = dataset['Close'].rolling(window=20).std()\n",
    "   dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*1.96)\n",
    "   dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*1.96)\n",
    "   \n",
    "   # Create Exponential moving average\n",
    "   dataset['ema'] = dataset['Close'].ewm(com=0.5).mean()\n",
    "   \n",
    "   # Create Momentum\n",
    "   dataset['momentum'] = dataset['Close']-dataset['Close'].shift(10)\n",
    "    \n",
    "   # Create Average True Range\n",
    "   dataset['HLrange'] = (dataset['High']-dataset['Low']).abs()\n",
    "   dataset['HCrange'] = (dataset['High']-dataset['Close'].shift(1)).abs()\n",
    "   dataset['CLrange'] = (dataset['Close'].shift(1)-dataset['Low']).abs()\n",
    "   dataset['TR'] = dataset.loc[:,['HLrange','HCrange','CLrange']].max(axis=1)\n",
    "   dataset['ATR'] = dataset['TR'].rolling(window=20).mean()\n",
    "    \n",
    "   # Create Volume Ratio\n",
    "   dataset['Vlchange'] = dataset['Volume'] - dataset['Volume'].shift(1)\n",
    "   dataset['VR'] = dataset['Vlchange'].rolling(window=14).apply(addPositive)/dataset['Vlchange'].rolling(window=14).apply(addNegative)\n",
    "   \n",
    "   # Create William Ratio\n",
    "   dataset['WR'] =  (dataset['High'].rolling(window=14).max()-dataset['Close']) \\\n",
    "    /(dataset['High'].rolling(window=14).max()-dataset['Low'].rolling(window=14).min())*100\n",
    "    \n",
    "   # Create Money Flow Index\n",
    "   dataset['MoneyFlow'] = dataset.loc[:,['High','Low','Close']].mean(axis=1)*dataset['Volume']\n",
    "   dataset['Mfchange'] = dataset['MoneyFlow'] - dataset['MoneyFlow'].shift(1)\n",
    "   dataset['MFI'] = dataset['Vlchange'].rolling(window=14).apply(addPositive)/dataset['Vlchange'].rolling(window=14).apply(addNegative)\n",
    "   \n",
    "   # Create Open-Close Range\n",
    "   dataset['OCR'] = dataset['Open']-dataset['Close'].shift(1)\n",
    "\n",
    "   return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolled_data(X,y,rolling_num=30):\n",
    "    X_roll = []\n",
    "    y_roll = []\n",
    "    for i in range(rolling_num, X.shape[0]):\n",
    "        X_roll.append(X[i-rolling_num:i,:])\n",
    "        y_roll.append(y[i, 0])\n",
    "    X_roll, y_roll = np.array(X_roll), np.array(y_roll)\n",
    "\n",
    "    print(X_roll.shape)\n",
    "    print(y_roll.shape)\n",
    "\n",
    "    # Reshaping\n",
    "    X_roll = np.reshape(X_roll, (X_roll.shape[0], X_roll.shape[1], X_roll.shape[2]))\n",
    "    y_roll = np.reshape(y_roll,(y_roll.shape[0],1))\n",
    "    \n",
    "    return X_roll,y_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "modelName = \"final_model\"\n",
    "model_path = os.path.join(\".\", modelName)\n",
    "\n",
    "def saveModel(model, model_path): \n",
    "    try:\n",
    "        os.makedirs(model_path)\n",
    "    except OSError:\n",
    "        print(\"Directory {dir:s} already exists, files will be over-written.\".format(dir=model_path))\n",
    "        \n",
    "    # Save JSON config to disk\n",
    "    json_config = model.to_json()\n",
    "    with open(os.path.join(model_path, 'config.json'), 'w') as json_file:\n",
    "        json_file.write(json_config)\n",
    "    # Save weights to disk\n",
    "    model.save_weights(os.path.join(model_path, 'weights.h5'))\n",
    "    \n",
    "    print(\"Model saved in directory {dir:s}; create an archive of this directory and submit with your assignment.\".format(dir=model_path))\n",
    "    \n",
    "def loadModel(model_path):\n",
    "    # Reload the model from the 2 files we saved\n",
    "    with open(os.path.join(model_path, 'config.json')) as json_file:\n",
    "        json_config = json_file.read()\n",
    "    model = tf.keras.models.model_from_json(json_config)\n",
    "    model.load_weights(os.path.join(model_path, 'weights.h5'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def MyModel(test_dir, model_path):\n",
    "    # YOU MAY NOT change model after this statement !\n",
    "    model = loadModel(model_path)\n",
    "    \n",
    "    # It should run model to create an array of predictions; we initialize it to the empty array for convenience\n",
    "    predictions = []\n",
    "    \n",
    "    # We need to match your array of predictions with the examples you are predicting\n",
    "    # The array below (ids) should have a one-to-one correspondence and identify the example your are predicting\n",
    "    # For Bankruptcy: the Id column\n",
    "    # For Stock prediction: the date on which you are making a prediction\n",
    "    ids = []\n",
    "    \n",
    "    # read data\n",
    "    data = pd.read_csv(test_dir+'\\AAPL.csv',parse_dates=True, index_col = \"Dt\")\n",
    "    data = data.iloc[:,[0,1,4,5,6,7]]\n",
    "    \n",
    "    #prepare the data\n",
    "    data_new = get_technical_indicators(data)\n",
    "    data_new['Return'] = data_new['Close'].pct_change()\n",
    "    data_new = data_new.dropna()\n",
    "    \n",
    "    X_test = data_new.loc[:,['High', 'Low', 'Open', 'Volume','ma7', 'ma21','26ema', '12ema', 'MACD','upper_band', 'lower_band', 'ema',\n",
    "       'momentum','ATR','VR', 'WR','MFI', 'OCR']]\n",
    "    y_test = data_new.loc[:,['Return']]\n",
    "    \n",
    "    sc_x = MinMaxScaler()\n",
    "    sc_y = MinMaxScaler()\n",
    "    X_test = sc_x.fit_transform(X_test)\n",
    "\n",
    "    y_test = sc_y.fit_transform(y_test)\n",
    "    \n",
    "    rolling_num=15\n",
    "    X_test_roll,y_test_roll = create_rolled_data(X_test,y_test,rolling_num=rolling_num)\n",
    "    ids = list(data_new.index[rolling_num:])\n",
    "    predicted = model.predict(X_test_roll)\n",
    "    predicted_stock_return = sc_y.inverse_transform(predicted)\n",
    "    \n",
    "    predictions = list(predicted_stock_return.T[0])\n",
    "    #print(len(predictions),len(ids))\n",
    "    \n",
    "    return predictions, ids\n",
    "\n",
    "# Assign to variable my_model the model that is your final model (the one  you will be evaluated on)\n",
    "#my_model = None # CHANGE None to your model !\n",
    "\n",
    "#saveModel(my_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model on the holdout data directory\n",
    "\n",
    "**You must run the following cell** from the directory that contains your model file\n",
    "\n",
    "Here is how we will evaluate your submission\n",
    "- we will create a directory whose only content is\n",
    "    - sub-directory `Data`\n",
    "- we will copy your model file to this directory with the name stored in `model_path`\n",
    "- we will run the cell in your notebook that should be a copy of the one below\n",
    "    - it calls procedure `MyModel` with the arguments given below\n",
    "    - your implementation of `MyModel`\n",
    "        - must successfully load your model file, *given where **we** have place it as described above*\n",
    "        - must successfully return one prediction for each example in the holdout directory *given where **we** have placed the holdout directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "(216, 15, 18)\n",
      "(216,)\n"
     ]
    }
   ],
   "source": [
    "#holdout_dir = os.path.join(\".\", \"Data\", \"sample\")\n",
    "#predicts = MyModel(holdout_dir, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_dir = os.path.join(\".\", \"Data\", \"holdout\")\n",
    "predicts = MyModel(holdout_dir, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
